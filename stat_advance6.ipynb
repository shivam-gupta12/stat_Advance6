{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11640876-a837-4639-80e2-043e57af6494",
   "metadata": {},
   "source": [
    "# question 1\n",
    "\n",
    "# Assumptions of ANOVA\n",
    "\n",
    "Normality: The data within each group should follow a normal distribution. This assumption can be checked using a histogram or a normal probability plot.\n",
    "\n",
    "Homogeneity of Variance: The variances of each group should be equal. This assumption can be checked using a plot of the group means versus the group standard deviations or by performing a Levene's test.\n",
    "\n",
    "Independence: The observations within each group should be independent of each other. This assumption is usually met if the groups are randomly sampled.\n",
    "\n",
    "Absence of Outliers: If there are outliers in the dataset, some or the other technique must be used in order to remove them.\n",
    "\n",
    "If these assumptions are violated, it may result in inaccurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb8777-98b5-4bec-b003-3b94e758ded6",
   "metadata": {},
   "source": [
    "# question 2\n",
    "\n",
    "The three types of ANOVA are :-\n",
    "\n",
    "1. One Way ANOVA- Here one factor is there with atleast two levels which are independent of each other.\n",
    "\n",
    "2. Repeated Measure ANOVA :- Here one factor is there with atleast two levels which are dependent on each other.\n",
    "\n",
    "3. Factorial ANOVA:- Here two or more factors are there with atleast two levels . It does not matter if they are independent or dependent on each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e3ea9-4044-4d92-be0c-d48cc9cfedc0",
   "metadata": {},
   "source": [
    "# question 3\n",
    "\n",
    "Partitioning of variance in ANOVA refers to the process of dividing the total variance in a data set into different components, each of which can be attributed to a particular source of variation. ANOVA achieves this by comparing the variation within groups to the variation between groups.\n",
    "\n",
    "The total variation in a data set can be broken down into two main components: variation within groups and variation between groups. Variation within groups is the variation that exists among the observations within each group or treatment. Variation between groups is the variation that exists among the means of the groups or treatments.\n",
    "\n",
    "By partitioning the variance, ANOVA can determine whether the observed differences between group means are statistically significant or not. This helps researchers to determine whether any differences observed between groups are likely due to chance or whether they are the result of a systematic effect of the independent variable(s) being studied.\n",
    "\n",
    "Understanding the concept of partitioning of variance is important in ANOVA because it allows researchers to assess the significance of the effects of different factors on the outcome variable. It also provides a way to identify potential sources of variation that may be contributing to differences between groups. This information can be useful in designing experiments and interpreting results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2bb6b8-63d6-4c5e-8b0a-8706a19b6b85",
   "metadata": {},
   "source": [
    "# question 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebbc912-4baa-4961-8fd9-b8986af71736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 280.0\n",
      "Explained sum of squares (SSE): 250.0\n",
      "Residual sum of squares (SSR): 30.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Create some sample data\n",
    "group1 = np.array([4, 7, 6, 8, 5])\n",
    "group2 = np.array([9, 11, 13, 10, 12])\n",
    "group3 = np.array([16, 14, 17, 15, 18])\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the mean of the combined data\n",
    "grand_mean = np.mean(data)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "SST = np.sum((data - grand_mean)**2)\n",
    "\n",
    "# Calculate the sum of squares explained by the groups (SSE)\n",
    "group_means = np.array([np.mean(group1), np.mean(group2), np.mean(group3)])\n",
    "SSE = np.sum((group_means - grand_mean)**2 * 5)\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total sum of squares (SST):\", SST)\n",
    "print(\"Explained sum of squares (SSE):\", SSE)\n",
    "print(\"Residual sum of squares (SSR):\", SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10923374-5dbe-4590-8ac4-95edefc4b93d",
   "metadata": {},
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3b91c6-53e2-4712-bf0d-835a20365711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             sum_sq    df         F    PR(>F)\n",
      "C(factor_a)                0.016209   1.0  0.003944  0.950210\n",
      "C(factor_b)                2.470619   2.0  0.300575  0.741901\n",
      "C(factor_a):C(factor_b)    6.946764   2.0  0.845142  0.436349\n",
      "Residual                 180.832172  44.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(123)\n",
    "n = 50\n",
    "factor_a = np.random.choice(['A1', 'A2'], size=n)\n",
    "factor_b = np.random.choice(['B1', 'B2', 'B3'], size=n)\n",
    "response = np.random.normal(loc=10, scale=2, size=n)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "data = pd.DataFrame({'factor_a': factor_a, 'factor_b': factor_b, 'response': response})\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('response ~ C(factor_a) + C(factor_b) + C(factor_a):C(factor_b)', data=data).fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(sm.stats.anova_lm(model, typ=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc6344-36ee-46d4-8826-dbef7dbcf247",
   "metadata": {},
   "source": [
    "# question 6\n",
    "\n",
    "A one-way ANOVA tests the null hypothesis that there are no differences in means between the groups. The F-statistic is a measure of how much the variance between the group means differs from what we would expect based on the variance within the groups alone. The p-value tells us the probability of observing such a large F-statistic by chance, assuming that the null hypothesis is true.\n",
    "\n",
    "In this case, the obtained F-statistic of 5.23 indicates that there is some difference between the group means. The p-value of 0.02 means that if the null hypothesis of no differences between the groups were true, there is a 2% chance of observing an F-statistic as large as 5.23 or larger. This is a relatively low probability, so we can reject the null hypothesis at the 5% significance level and conclude that there are significant differences between the groups.\n",
    "\n",
    "In other words, we can conclude that at least one of the groups has a different mean from the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8212289-3e9b-4891-a4ff-ca657395fbca",
   "metadata": {},
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb6db6-92b3-4684-ba30-3750eef5a8ae",
   "metadata": {},
   "source": [
    "One approach to handling missing data is to exclude cases with missing data from the analysis, commonly referred to as listwise deletion. However, this approach can reduce the sample size and statistical power of the analysis, potentially leading to biased or inaccurate results. In addition, listwise deletion assumes that the missing data are missing completely at random (MCAR), which may not be a realistic assumption in practice.\n",
    "\n",
    "Another approach is to impute the missing data, which involves estimating the missing values based on the available data. There are several methods of imputation, such as mean imputation, regression imputation, and multiple imputation. Mean imputation replaces missing values with the mean of the observed values for that variable, while regression imputation uses a regression model to estimate the missing values based on the other variables in the data set. Multiple imputation involves creating several imputed data sets and then analyzing each of them separately before combining the results.\n",
    "\n",
    "Imputation can improve the precision and validity of the analysis, but it also has limitations. Imputation assumes that the missing data are missing at random (MAR), which means that the probability of missing data depends only on the observed data and not on unobserved data. If the missing data are not MAR, imputation can lead to biased or inaccurate results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a156fe-37e7-4e24-b7b5-3cea8a44212d",
   "metadata": {},
   "source": [
    "# question 8\n",
    "\n",
    "Most common post- hoc methods are:-\n",
    "\n",
    "Tukey's HSD (Honestly Significant Difference): Tukey's HSD is a widely used post-hoc test that compares all possible pairs of group means and controls the family-wise error rate. This test is appropriate when there are no specific a priori hypotheses about which groups may be different from each other.\n",
    "\n",
    "Bonferroni correction: The Bonferroni correction is a conservative approach that adjusts the alpha level (i.e., the significance level) for multiple comparisons. It is appropriate when there are specific a priori hypotheses about which groups may be different from each other.\n",
    "\n",
    "Scheffe's method: Scheffe's method is a conservative post-hoc test that controls the family-wise error rate. It is appropriate when there are multiple comparisons and the sample sizes are unequal.\n",
    "\n",
    "Games-Howell test: The Games-Howell test is a non-parametric post-hoc test that does not assume equal variances among the groups. It is appropriate when the assumption of equal variances is violated.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is in a study comparing the effects of three different treatments (Treatment A, B, and C) on a dependent variable. After conducting a one-way ANOVA, the researcher finds a significant main effect of treatment. To determine which treatments are significantly different from each other, a post-hoc test such as Tukey's HSD or Bonferroni correction can be used. For instance, Tukey's HSD can be used to test all possible pairs of group means, while Bonferroni correction can be used to test specific a priori hypotheses about which groups may be different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db6897c-4fa1-4710-a292-2ab46f4890e1",
   "metadata": {},
   "source": [
    "# question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4f6d85-33bb-4ddc-bd6e-7e0fef15c95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic:  22.245732108190538\n",
      "p-value:  3.6294576915534843e-09\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# create data\n",
    "np.random.seed(123)\n",
    "diet_a = np.random.normal(loc=5, scale=2, size=50)\n",
    "diet_b = np.random.normal(loc=7, scale=2, size=50)\n",
    "diet_c = np.random.normal(loc=4, scale=2, size=50)\n",
    "\n",
    "# create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'diet': ['A']*50 + ['B']*50 + ['C']*50,\n",
    "    'weight_loss': np.concatenate((diet_a, diet_b, diet_c))\n",
    "})\n",
    "\n",
    "# conduct one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "# print results\n",
    "print(\"F-statistic: \", f_statistic)\n",
    "print(\"p-value: \", p_value)\n",
    "\n",
    "# since the f statistic is large and p value is small \n",
    "#we can reject the null hypothesis that there is no difference in the mean weight loss between the three diets \n",
    "#and conclude that there are significant differences between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9ce2f-1208-4790-a4ae-24da4ba87a86",
   "metadata": {},
   "source": [
    "# question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be50aae-6bac-453f-8217-e2fdf8cc89b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(software)                 17.386324   2.0  1.702921  0.188378\n",
      "C(experience)                8.604884   1.0  1.685628  0.197732\n",
      "C(software):C(experience)   18.813443   2.0  1.842701  0.164734\n",
      "Residual                   428.807757  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# generate data\n",
    "np.random.seed(123)\n",
    "time_data = np.random.normal(loc=10, scale=2, size=90)\n",
    "software = ['A', 'B', 'C'] * 30\n",
    "experience = ['novice'] * 45 + ['experienced'] * 45\n",
    "\n",
    "# create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'time': time_data,\n",
    "    'software': software,\n",
    "    'experience': experience\n",
    "})\n",
    "\n",
    "# conduct two-way ANOVA\n",
    "model = ols('time ~ C(software) + C(experience) + C(software):C(experience)', data=df).fit()\n",
    "table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print results\n",
    "print(table)\n",
    "\n",
    "#If the p-value for an effect is less than 0.05, \n",
    "#we can reject the null hypothesis and conclude that the effect is statistically significant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e05f0-c296-4ca5-8065-5fa44079d684",
   "metadata": {},
   "source": [
    "# question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdb762d2-e0c7-4f62-b5ba-acbf1b54a26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -4.508893097370603\n",
      "p-value: 1.8080222016909692e-05\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj lower   upper  reject\n",
      "---------------------------------------------------------\n",
      "control experimental  10.2768   0.0 5.7537 14.7998   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# generate data\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=50)\n",
    "experimental_scores = np.random.normal(loc=80, scale=10, size=50)\n",
    "\n",
    "# conduct two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "print('t-statistic:', t_stat)\n",
    "print('p-value:', p_value)\n",
    "\n",
    "# conduct post-hoc test\n",
    "df = pd.DataFrame({\n",
    "    'score': np.concatenate([control_scores, experimental_scores]),\n",
    "    'group': ['control'] * 50 + ['experimental'] * 50\n",
    "})\n",
    "posthoc = pairwise_tukeyhsd(df['score'], df['group'])\n",
    "print(posthoc)\n",
    "\n",
    "\n",
    "#The p-value is a measure of the strength of evidence against the null hypothesis. \n",
    "#In this case, the p-value is very small (1.8080222016909692e-05), \n",
    "#which means that the probability of observing such a large difference in means by chance alone is very low\n",
    "#we reject the null hypothesis and conclude that there is a significant difference in test scores between the control and experimental groups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ea1ce-6f5b-4d72-bae2-a6bfcab68153",
   "metadata": {},
   "source": [
    "# question 12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5185e601-3773-466e-81b8-4e13b843b0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 sum_sq    df          F    PR(>F)\n",
      "Store       5305.706697   2.0  13.866440  0.000006\n",
      "Day         1025.476816   1.0   5.360158  0.023041\n",
      "Store:Day   1619.464303   2.0   4.232463  0.017729\n",
      "Residual   16070.431896  84.0        NaN       NaN\n",
      "There is a significant difference between at least one pair of stores\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "     A      B  11.6751 0.0077  2.6451 20.7051   True\n",
      "     A      C  18.6068    0.0  9.5768 27.6368   True\n",
      "     B      C   6.9317 0.1658 -2.0983 15.9617  False\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "from scipy import stats\n",
    "\n",
    "# generate sales data (using the code provided in the previous answer)\n",
    "np.random.seed(123)\n",
    "sales_A = np.random.normal(50, 10, 30)\n",
    "sales_B = np.random.normal(60, 15, 30)\n",
    "sales_C = np.random.normal(70, 12, 30)\n",
    "data = {'Store': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "        'Day': list(range(1,31))*3,\n",
    "        'Sales': np.concatenate((sales_A, sales_B, sales_C))}\n",
    "sales_data  = pd.DataFrame(data)\n",
    "\n",
    "# create a model for repeated measures ANOVA using the formula notation\n",
    "model = ols('Sales ~ Store + Day + Store:Day', data=df).fit()\n",
    "\n",
    "# get ANOVA table and print results\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# conduct post-hoc test (Tukey HSD) if the ANOVA results are significant\n",
    "if anova_table['PR(>F)'][0] < 0.05:\n",
    "    print(\"There is a significant difference between at least one pair of stores\")\n",
    "\n",
    "    # Perform the Tukey's HSD post-hoc test\n",
    "    mc = MultiComparison(sales_data['Sales'], sales_data['Store'])\n",
    "    result = mc.tukeyhsd()\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"There is no significant difference between any pair of stores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ac6a6-6408-4337-a9b6-fe0c1d2648da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
